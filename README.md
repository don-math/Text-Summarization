# Text-Summarization

In this project, we evaluate the performances of two models: Pegasus and GPT-3 on text summarization.

First, we generate summaries using baseline methods, pegasus, and GPT-3 before and after fine-tuning . Then we evaluate the quality of these generations using the ROUGE metric. Since the evaluation metric is still a field of active research, to compensate for the weakness of ROUGE, we manually evaluate the quality of a sampled summary.
